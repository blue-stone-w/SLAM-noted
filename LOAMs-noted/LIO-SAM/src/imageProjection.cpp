/*
Description: [incre=incremental, estimated=optimized, preint=preintegration, lo=lidarodometry]
1.class TransformFusion:
pub pose( =imu preint+global pose(generated by map optimization node, which include loop closure) )
2.class IMUPreintegration:
cachePointCloud: cache Cloud and check whether cloud data is valid for this program
Author     : Wang Junpeng
date       :
*/

#include "utility.h"
#include "lio_sam/cloud_info.h"

struct VelodynePointXYZIRT
{
  PCL_ADD_POINT4D
  PCL_ADD_INTENSITY;
  uint16_t ring; // 距离矩阵中的每一行为一个ring
  float time;
  EIGEN_MAKE_ALIGNED_OPERATOR_NEW // 确保定义新类型点云内存与SSE对齐
} EIGEN_ALIGN16;                  // 强制SSE填充以正确对齐内存
// 注册点云： User defined point structures can be registered using PCL macros.
// 定义新类型里元素包括XYZI+ring+time, time is for undistort,ring is for projecting cloud to range image
POINT_CLOUD_REGISTER_POINT_STRUCT(VelodynePointXYZIRT,
                                  (float, x, x)(float, y, y)(float, z, z)(float, intensity, intensity)(uint16_t, ring, ring)(float, time, time))

struct OusterPointXYZIRT
{
  PCL_ADD_POINT4D;
  float intensity;
  uint32_t t;
  uint16_t reflectivity;
  uint8_t ring;
  uint16_t noise;
  uint32_t range;
  EIGEN_MAKE_ALIGNED_OPERATOR_NEW
} EIGEN_ALIGN16;
POINT_CLOUD_REGISTER_POINT_STRUCT(OusterPointXYZIRT,
                                  (float, x, x)(float, y, y)(float, z, z)(float, intensity, intensity)(uint32_t, t, t)(uint16_t, reflectivity, reflectivity)(uint8_t, ring, ring)(uint16_t, noise, noise)(uint32_t, range, range))

// Use the Velodyne point format as a common representation
using PointXYZIRT = VelodynePointXYZIRT;

const int queueLength = 2000; // max num of saves imu data
/**
 * 点云投影成深度图,类似lego loam中的做法
 * 列表示线束数量，行表示横向解析度，比如16*1800,横向解析度则为0.2
 */
class ImageProjection : public ParamServer
{
private:
  std::mutex imuLock;
  std::mutex odoLock;

  ros::Subscriber subLaserCloud;
  ros::Publisher pubLaserCloud;

  ros::Publisher pubExtractedCloud;
  ros::Publisher pubLaserCloudInfo;

  ros::Subscriber subImu;
  std::deque<sensor_msgs::Imu> imuQueue;

  ros::Subscriber subOdom;
  std::deque<nav_msgs::Odometry> odomQueue;

  std::deque<sensor_msgs::PointCloud2> cloudQueue;
  sensor_msgs::PointCloud2 currentCloudMsg;

  double *imuTime = new double[queueLength];
  double *imuRotX = new double[queueLength]; // use as loop queue
  double *imuRotY = new double[queueLength];
  double *imuRotZ = new double[queueLength];

  int imuPointerCur;                 // num of imu pointer that can be used to deskew
  bool firstPointFlag;               // whether it is first point in this cloud
  Eigen::Affine3f transStartInverse; // 点云的首个点的位姿的逆

  pcl::PointCloud<PointXYZIRT>::Ptr laserCloudIn;
  pcl::PointCloud<OusterPointXYZIRT>::Ptr tmpOusterCloudIn;
  pcl::PointCloud<PointType>::Ptr fullCloud;
  pcl::PointCloud<PointType>::Ptr extractedCloud; // 保存去除了无效点的点云

  int deskewFlag; // "=-1": Point cloud timestamp not available, deskew function disabled,
  cv::Mat rangeMat;

  bool odomDeskewFlag; // odom 是否可用于畸变补偿
  float odomIncreX;    // odom 在该帧点云期间的增量
  float odomIncreY;
  float odomIncreZ;

  lio_sam::cloud_info cloudInfo;
  double timeScanCur; // scan start moment
  double timeScanEnd; // scan end moment
  std_msgs::Header cloudHeader;

public:
  ImageProjection() : deskewFlag(0)
  { // subscriber, 订阅imu和odometry以及原始点云，这里的odom应该是 gps+imu 通过 robot_localization 包融合得到的.???
    // imu和odom callback中主要是用来装数据
    subImu = nh.subscribe<sensor_msgs::Imu>(imuTopic, 2000, &ImageProjection::imuHandler, this,
                                            ros::TransportHints().tcpNoDelay()); // 允许指定hints到roscpp的传输层
    // imu odom incre
    subOdom = nh.subscribe<nav_msgs::Odometry>(odomTopic + "_incremental", 2000, &ImageProjection::odometryHandler, this, ros::TransportHints().tcpNoDelay());
    // 点云处理的逻辑全部在cloudHandler中
    subLaserCloud = nh.subscribe<sensor_msgs::PointCloud2>(pointCloudTopic, 5, &ImageProjection::cloudHandler, this, ros::TransportHints().tcpNoDelay());

    // publisher, 发布自定义的cloud_info和用于odometry的cloud
    pubExtractedCloud = nh.advertise<sensor_msgs::PointCloud2>("lio_sam/deskew/cloud_deskewed", 1);
    pubLaserCloudInfo = nh.advertise<lio_sam::cloud_info>("lio_sam/deskew/cloud_info", 1);

    allocateMemory(); // only define pointer before, here allocate for pointer
    resetParameters();
    // setVerbosityLevel:用于设置控制台输出的信息(设置冗长级别)
    //  L_ALWAYS:不会输出任何信息；L_DEBUG:输出DEBUG信息
    //  L_INFO,;L_VERBOSE
    pcl::console::setVerbosityLevel(pcl::console::L_ERROR);
  }

  ~ImageProjection() {}

  void imuHandler(const sensor_msgs::Imu::ConstPtr &imuMsg)
  {
    // 将imu数据转到lidar坐标系下, 这里在params中配置过imu到lidar的外参
    sensor_msgs::Imu thisImu = imuConverter(*imuMsg);
    // define a thread lock of imu lock. unlock will be operated when lock_guard is destructed.
    std::lock_guard<std::mutex> lock1(imuLock);
    imuQueue.push_back(thisImu);
    // debug IMU data
    // cout << std::setprecision(6);
    // cout << "IMU acc: " << endl;
    // cout << "x: " << thisImu.linear_acceleration.x <<
    //       ", y: " << thisImu.linear_acceleration.y <<
    //       ", z: " << thisImu.linear_acceleration.z << endl;
    // cout << "IMU gyro: " << endl;
    // cout << "x: " << thisImu.angular_velocity.x <<
    //       ", y: " << thisImu.angular_velocity.y <<
    //       ", z: " << thisImu.angular_velocity.z << endl;
    // double imuRoll, imuPitch, imuYaw;
    // tf::Quaternion orientation;
    // tf::quaternionMsgToTF(thisImu.orientation, orientation);
    // tf::Matrix3x3(orientation).getRPY(imuRoll, imuPitch, imuYaw);
    // cout << "IMU roll pitch yaw: " << endl;
    // cout << "roll: " << imuRoll << ", pitch: " << imuPitch << ", yaw: " << imuYaw << endl << endl;
  }

  void odometryHandler(const nav_msgs::Odometry::ConstPtr &odometryMsg)
  {
    // 锁存后装数据
    std::lock_guard<std::mutex> lock2(odoLock);
    odomQueue.push_back(*odometryMsg);
  }

  void cloudHandler(const sensor_msgs::PointCloud2ConstPtr &laserCloudMsg)
  {
    // whether laser cloud is valid; get new cloud，并检查当前点云帧里面是否有ring和time通道
    if (!cachePointCloud(laserCloudMsg))
      return;

    /*配置好用于去畸变的imu和odom参数 before --->
      找到点云时间戳前后的GPS odom和imu 数据 --->
      并分别计算在这两帧时间内的位姿增量和旋转增量
    */
    if (!deskewInfo())
      return;

    // 点云投影成深度图->去畸变
    projectPointCloud();

    // 从深度图中提取点云, 给lidar odometry用
    cloudExtraction();

    // 发布点云
    publishClouds();

    // 重置参数
    resetParameters();
  }

  bool cachePointCloud(const sensor_msgs::PointCloud2ConstPtr &laserCloudMsg)
  {
    // cache point cloud
    cloudQueue.push_back(*laserCloudMsg);
    if (cloudQueue.size() <= 2)
      return false;

    // when cache enough cloud, convert cloud; 点云队列先进先出,最早的点云存到currentCloudMsg
    currentCloudMsg = std::move(cloudQueue.front());
    cloudQueue.pop_front(); // delete old cloud
    // PointXYZIRT:intensity,ring,time; laserCloudIn; 这里得到的已经是下一帧的数据了(最新)
    if (sensor == SensorType::VELODYNE)
    {
      pcl::moveFromROSMsg(currentCloudMsg, *laserCloudIn); // 将点云消息添加进点云指针
    }
    else if (sensor == SensorType::OUSTER)
    {

      // 从ros消息转换为OusterPointXYZIRT格式的点云
      pcl::moveFromROSMsg(currentCloudMsg, *tmpOusterCloudIn);
      laserCloudIn->points.resize(tmpOusterCloudIn->size());
      laserCloudIn->is_dense = tmpOusterCloudIn->is_dense; // 稠密点云
      // Convert to Velodyne format
      for (size_t i = 0; i < tmpOusterCloudIn->size(); i++)
      {
        auto &src = tmpOusterCloudIn->points[i];
        auto &dst = laserCloudIn->points[i];
        dst.x = src.x;
        dst.y = src.y;
        dst.z = src.z;
        dst.intensity = src.intensity;
        dst.ring = src.ring;
        dst.time = src.t * 1e-9f;
      }
    }
    else
    {
      ROS_ERROR_STREAM("Unknown sensor type: " << int(sensor));
      ros::shutdown();
    }

    // get timestamp
    cloudHeader = currentCloudMsg.header;
    timeScanCur = cloudHeader.stamp.toSec();                      // absolute time
    timeScanEnd = timeScanCur + laserCloudIn->points.back().time; // point time is relative time

    // check dense flag; "is_dense = true" means points is in order
    if (laserCloudIn->is_dense == false)
    {
      ROS_ERROR("Point cloud is not in dense format, please remove NaN points first!");
      ros::shutdown();
    }

    // check ring channel; whether include information that every point in which scan(horizontal)
    // veloodyne和ouster都有中才有ring通道,不然需要自行计算
    static int ringFlag = 0;
    if (ringFlag == 0)
    {
      ringFlag = -1;
      // Each field consists of a varible type and a varible name
      // all varible names in msg are saved in "fields"
      for (int i = 0; i < (int)currentCloudMsg.fields.size(); ++i)
      {
        // traverse fields to fint out whether exist a varible named in "ring"
        // ring indicates point locate in which scan(horizontal)
        if (currentCloudMsg.fields[i].name == "ring")
        {
          ringFlag = 1;
          break;
        }
      }
      // if no scan id, should calculate scan id like loam or lego. velodyne usually contain these info
      if (ringFlag == -1)
      {
        ROS_ERROR("Point cloud ring channel not available, please configure your point cloud data!");
        ros::shutdown();
      }
    }

    // check point time(relative)
    if (deskewFlag == 0)
    {
      deskewFlag = -1;
      for (auto &field : currentCloudMsg.fields)
      {
        // name may be these two words. you can add more names or delete it as your will
        if (field.name == "time" || field.name == "t")
        {
          deskewFlag = 1;
          break;
        }
      }
      if (deskewFlag == -1)
      {
        ROS_WARN("Point cloud timestamp not available, deskew function disabled, system will drift significantly!");
      }
    }
    return true;
  }

  // get info for deskew, whether there are data to deskew
  // for kitti dataset, cloud has been deskewed
  bool deskewInfo()
  {
    std::lock_guard<std::mutex> lock1(imuLock);
    std::lock_guard<std::mutex> lock2(odoLock);

    // make sure IMU data available for the scan and imu data cover this scan cloud in time
    // 保证imu和odom数据，并且当前帧点云数据, 其时间戳在队列中的imu数据之间
    if (imuQueue.empty() ||
        imuQueue.front().header.stamp.toSec() > timeScanCur ||
        imuQueue.back().header.stamp.toSec() < timeScanEnd)
    {
      ROS_DEBUG("Waiting for IMU data ...");
      return false;
    }

    // prepare imu data for deskew; 遍历imu队列, 计算点云帧对应的imu数据, 包括积分计算其转过的角度,用于后续去畸变
    imuDeskewInfo();

    // odom from imu preint node; prepare odom data for deskew
    odomDeskewInfo();
    return true;
  }

  void imuDeskewInfo()
  {
    // 这个参数在地图优化程序中用到  首先为false 完成相关操作后置true ???
    cloudInfo.imuAvailable = false;
    while (!imuQueue.empty())
    { // pop old imu data that earlier than first point of cloud
      // 0.01 is allowance to avoid pop needed imu data
      // timeScanCur指当前点云帧的时间戳
      if (imuQueue.front().header.stamp.toSec() < timeScanCur - 0.01)
      {
        imuQueue.pop_front();
      }
      else
        break;
    }

    if (imuQueue.empty())
      return;

    imuPointerCur = 0;

    for (int i = 0; i < (int)imuQueue.size(); ++i)
    {
      sensor_msgs::Imu thisImuMsg = imuQueue[i];
      double currentImuTime = thisImuMsg.header.stamp.toSec();
      // get roll, pitch, and yaw estimation for this scan
      if (currentImuTime <= timeScanCur)
      {
        // convert imu pose to Euler as pose at cloud start moment
        // 用imu的欧拉角做扫描的位姿估计,直接把值给了cloudInfo在地图优化程序中使用
        imuRPY2rosRPY(&thisImuMsg, &cloudInfo.imuRollInit, &cloudInfo.imuPitchInit, &cloudInfo.imuYawInit);
      }

      // break if traverse this scan; 如果当前Imu时间比下一帧时间大于0.01退出, imu频率大于100hz才比较有用
      if (currentImuTime > timeScanEnd + 0.01)
        break;

      // 第一次初始化时以下值都是0
      if (imuPointerCur == 0)
      { // means start(first) scan
        imuRotX[0] = 0;
        imuRotY[0] = 0;
        imuRotZ[0] = 0;
        imuTime[0] = currentImuTime;
        ++imuPointerCur;
        continue;
      }

      // get angular velocity of this imu frame
      double angular_x, angular_y, angular_z;
      imuAngular2rosAngular(&thisImuMsg, &angular_x, &angular_y, &angular_z);

      // integrate rotation
      // get attitude angle at every moment to look up corresponding data of every point
      double timeDiff = currentImuTime - imuTime[imuPointerCur - 1];              // time fifference of two imu frame
      imuRotX[imuPointerCur] = imuRotX[imuPointerCur - 1] + angular_x * timeDiff; // integration
      imuRotY[imuPointerCur] = imuRotY[imuPointerCur - 1] + angular_y * timeDiff;
      imuRotZ[imuPointerCur] = imuRotZ[imuPointerCur - 1] + angular_z * timeDiff;
      imuTime[imuPointerCur] = currentImuTime;
      ++imuPointerCur;
    }

    --imuPointerCur;

    if (imuPointerCur <= 0)
      return; // (imu Pointer num > 1)

    // we can use imu data to deskew cloud
    cloudInfo.imuAvailable = true;
  }

  void odomDeskewInfo()
  {
    // when odom can cover this cloud in time, we use odom to deskew
    // cloud time    ***
    // odom time   *******
    // 类似imu数据,用于标志当前点云帧的odom处理的信息是否有效
    cloudInfo.odomAvailable = false;

    // pop old data
    while (!odomQueue.empty())
    {
      // 保证点云帧的时间戳在odom队列中间
      if (odomQueue.front().header.stamp.toSec() < timeScanCur - 0.01)
      {
        odomQueue.pop_front();
      }
      else
        break;
    }

    if (odomQueue.empty())
      return;
    // cloud time    ***
    // odom time      ****
    if (odomQueue.front().header.stamp.toSec() > timeScanCur)
      return;

    // get start odometry at the beinning of the scan
    // 遍历odom队列,将odom的位姿作为点云信息中预测位姿
    nav_msgs::Odometry startOdomMsg; // first odom data later than cloud start moment
    // look for first odom data later than cloud start moment
    for (int i = 0; i < (int)odomQueue.size(); ++i)
    {
      startOdomMsg = odomQueue[i];
      // 之前已经将小于timeScanCur超过0.01的数据弹出,所以startOdomMsg已经可代表起始激光扫描的起始时刻的里程计消息
      if (ROS_TIME(&startOdomMsg) < timeScanCur)
        continue;
      else
        break;
    }

    // convert pose from ros msg to tf quaternion
    tf::Quaternion orientation;
    tf::quaternionMsgToTF(startOdomMsg.pose.pose.orientation, orientation);

    // convert quaternion to Euler
    double roll, pitch, yaw;
    tf::Matrix3x3(orientation).getRPY(roll, pitch, yaw);

    // 用当前odom队列的起始位姿作为当前点云的初始位姿
    // save odom pose in cloud start moment, Initial guess used in mapOptimization
    cloudInfo.initialGuessX = startOdomMsg.pose.pose.position.x;
    cloudInfo.initialGuessY = startOdomMsg.pose.pose.position.y;
    cloudInfo.initialGuessZ = startOdomMsg.pose.pose.position.z;
    cloudInfo.initialGuessRoll = roll;
    cloudInfo.initialGuessPitch = pitch;
    cloudInfo.initialGuessYaw = yaw;

    cloudInfo.odomAvailable = true; // odom provide initial pose of this cloud frame

    // get end odometry at the end of the scan
    // 获得一帧扫描末尾的里程计消息,和初始位姿无关, 主要用于去畸变、运动补偿
    odomDeskewFlag = false;
    // if odom can't cover end of this scan, we can't use odom data to deskew
    // cloud time    ***
    // odom time   ****
    if (odomQueue.back().header.stamp.toSec() < timeScanEnd)
      return;

    nav_msgs::Odometry endOdomMsg; // corresponding odom data of end point of this cloud
    // find corresponding odom data of end point of this cloud
    for (int i = 0; i < (int)odomQueue.size(); ++i)
    {
      endOdomMsg = odomQueue[i];
      if (ROS_TIME(&endOdomMsg) < timeScanEnd)
        continue;
      else
        break;
    }

    // odom is degenerated, low confidence, we can't use to deskew
    if (int(round(startOdomMsg.pose.covariance[0])) != int(round(endOdomMsg.pose.covariance[0])))
      return;
    // convert start and end pose from pcl to affine
    Eigen::Affine3f transBegin = pcl::getTransformation(startOdomMsg.pose.pose.position.x,
                                                        startOdomMsg.pose.pose.position.y,
                                                        startOdomMsg.pose.pose.position.z,
                                                        roll, pitch, yaw);

    tf::quaternionMsgToTF(endOdomMsg.pose.pose.orientation, orientation);
    tf::Matrix3x3(orientation).getRPY(roll, pitch, yaw);
    Eigen::Affine3f transEnd = pcl::getTransformation(endOdomMsg.pose.pose.position.x,
                                                      endOdomMsg.pose.pose.position.y,
                                                      endOdomMsg.pose.pose.position.z,
                                                      roll, pitch, yaw);
    // // 获得一帧扫描起始与结束时刻间的变换, 参考loam: trans between = end - start
    Eigen::Affine3f transBt = transBegin.inverse() * transEnd;

    // 计算这个首尾odom的增量, 用于后续去畸变
    float rollIncre, pitchIncre, yawIncre;
    pcl::getTranslationAndEulerAngles(transBt, odomIncreX, odomIncreY, odomIncreZ, rollIncre, pitchIncre, yawIncre);

    odomDeskewFlag = true; // 标志位, odom can be used to deskew
  }

  // project cloud to range map/matrix and save info of every point
  void projectPointCloud()
  { // 将点云投影成深度图
    int cloudSize = laserCloudIn->points.size();
    // range image projection
    for (int i = 0; i < cloudSize; ++i)
    {
      PointType thisPoint;
      // get a point
      thisPoint.x = laserCloudIn->points[i].x;
      thisPoint.y = laserCloudIn->points[i].y;
      thisPoint.z = laserCloudIn->points[i].z;
      thisPoint.intensity = laserCloudIn->points[i].intensity;

      // range from point to lidar;
      float range = pointDistance(thisPoint);
      // invalid range(too far or too close)
      if (range < lidarMinRange || range > lidarMaxRange)
      {
        continue;
      }
      // 没有ring 的话需要依据垂直角度计算
      int rowIdn = laserCloudIn->points[i].ring; // in which scan/ring(horizonal) locate
      if (rowIdn < 0 || rowIdn >= N_SCAN)
        continue; // invalid row index
      if (rowIdn % downsampleRate != 0)
        continue; // skip some points when downsample

      // 激光点的水平角度, 计算一帧点云转过多少度，进而计算每个点投影到深度图中的列id和时间戳
      float horizonAngle = atan2(thisPoint.x, thisPoint.y) * 180 / M_PI;
      // 角分辨率 360/1800; resolution in x-axis
      static float ang_res_x = 360.0 / float(Horizon_SCAN);
      // for old lidar, we should calculate column index manully;
      // clockwise is forward direction; negative direction of x-axis is start direction
      int columnIdn = -round((horizonAngle - 90.0) / ang_res_x) + Horizon_SCAN / 2;
      if (columnIdn >= Horizon_SCAN)
        columnIdn -= Horizon_SCAN;
      if (columnIdn < 0 || columnIdn >= Horizon_SCAN)
        continue; // invalid column index

      // when cloud > 360, there is overlap. thus, it's possible that this position has been filled.
      if (rangeMat.at<float>(rowIdn, columnIdn) != FLT_MAX)
        continue;

      //  点云去畸变,运动补偿,这里需要用到雷达信息中的time这个field;
      thisPoint = deskewPoint(&thisPoint, laserCloudIn->points[i].time);
      // save range into range matrix
      rangeMat.at<float>(rowIdn, columnIdn) = range;
      // index of this point,索引值,类似于图像中像素索引的概念
      int index = columnIdn + rowIdn * Horizon_SCAN;
      // save coordinate of this point; 去完畸变的点云存储到fullCloud中
      fullCloud->points[index] = thisPoint;
    }
  }

  // 根据时间戳,对每个点去畸变
  PointType deskewPoint(PointType *point, double relTime)
  {

    if (deskewFlag == -1 || cloudInfo.imuAvailable == false)
      return *point;
    // rel time is relative time: rel time = point time - scan start moment
    double pointTime = timeScanCur + relTime; // point time is absolute time

    float rotXCur, rotYCur, rotZCur;
    // relative rotation from current point to start point
    findRotation(pointTime, &rotXCur, &rotYCur, &rotZCur);

    float posXCur, posYCur, posZCur;
    // here is no transformation conpensation
    findPosition(relTime, &posXCur, &posYCur, &posZCur);

    // 如果是第一帧数据
    if (firstPointFlag == true)
    {
      // relative pose of first point; pcl pose and rotation to eigen affine; 起始矩阵赋值再取逆
      transStartInverse = (pcl::getTransformation(posXCur, posYCur, posZCur, rotXCur, rotYCur, rotZCur)).inverse();
      firstPointFlag = false;
    }

    // relative transformation from current point to start point; transform points to start
    Eigen::Affine3f transFinal = pcl::getTransformation(posXCur, posYCur, posZCur, rotXCur, rotYCur, rotZCur);
    Eigen::Affine3f transBt = transStartInverse * transFinal; // this point - first point

    PointType newPoint;
    // deskew point to start moment
    newPoint.x = transBt(0, 0) * point->x + transBt(0, 1) * point->y + transBt(0, 2) * point->z + transBt(0, 3);
    newPoint.y = transBt(1, 0) * point->x + transBt(1, 1) * point->y + transBt(1, 2) * point->z + transBt(1, 3);
    newPoint.z = transBt(2, 0) * point->x + transBt(2, 1) * point->y + transBt(2, 2) * point->z + transBt(2, 3);
    newPoint.intensity = point->intensity;
    return newPoint;
  }

  void findRotation(double pointTime, float *rotXCur, float *rotYCur, float *rotZCur)
  {
    *rotXCur = 0;
    *rotYCur = 0;
    *rotZCur = 0;

    int imuPointerFront = 0;
    // imu Pointer Cur is size of imu rotation buffer; use imu Pointer Front to avoid "array out of bounds"
    while (imuPointerFront < imuPointerCur)
    { // find first imu data later than this point; 最终要保证点云时间在两帧imu数据中间
      if (pointTime < imuTime[imuPointerFront])
        break;
      ++imuPointerFront; // 当前point_time在imu_time前面，舍弃
    }

    // imu pointer back(late)        imu point front(early)
    //       *                             *
    //                     *
    //               imu pointer cur

    // if timestamp is not between this two moment(该点为点云的首个点，或者对应第一个imu数据);pointTime在imu队列的起点
    if (pointTime > imuTime[imuPointerFront] || imuPointerFront == 0)
    {
      *rotXCur = imuRotX[imuPointerFront];
      *rotYCur = imuRotY[imuPointerFront];
      *rotZCur = imuRotZ[imuPointerFront];
    }
    else
    { // point time is between two imu data, back is the later one , front is the earlier one
      // linear interpolation
      int imuPointerBack = imuPointerFront - 1;
      double ratioFront = (pointTime - imuTime[imuPointerBack]) / (imuTime[imuPointerFront] - imuTime[imuPointerBack]);
      double ratioBack = (imuTime[imuPointerFront] - pointTime) / (imuTime[imuPointerFront] - imuTime[imuPointerBack]);
      *rotXCur = imuRotX[imuPointerFront] * ratioFront + imuRotX[imuPointerBack] * ratioBack;
      *rotYCur = imuRotY[imuPointerFront] * ratioFront + imuRotY[imuPointerBack] * ratioBack;
      *rotZCur = imuRotZ[imuPointerFront] * ratioFront + imuRotZ[imuPointerBack] * ratioBack;
    }
  }

  void findPosition(double relTime, float *posXCur, float *posYCur, float *posZCur)
  {
    *posXCur = 0;
    *posYCur = 0;
    *posZCur = 0;
    // If the sensor moves relatively slow, like walking speed, positional deskew seems to have little benefits. Thus code below is commented.

    // if (cloudInfo.odomAvailable == false || odomDeskewFlag == false)
    //     return;

    // float ratio = relTime / (timeScanEnd - timeScanCur);

    // *posXCur = ratio * odomIncreX;
    // *posYCur = ratio * odomIncreY;
    // *posZCur = ratio * odomIncreZ;
  }

  void cloudExtraction()
  { // 提取点云给odometry

    int count = 0; // pocessing point index
    // extract segmented cloud for lidar odometry
    for (int i = 0; i < N_SCAN; ++i)
    {
      cloudInfo.startRingIndex[i] = count - 1 + 5; // discard first 5 point of every ring

      for (int j = 0; j < Horizon_SCAN; ++j)
      {
        if (rangeMat.at<float>(i, j) != FLT_MAX)
        { // invalid range; 图像上不一定每个位置都有点，只取有深度的点
          // mark the points' column index for marking occlusion later
          cloudInfo.pointColInd[count] = j;
          // save range info
          cloudInfo.pointRange[count] = rangeMat.at<float>(i, j);
          // save extracted cloud, 3d coordiate
          extractedCloud->push_back(fullCloud->points[j + i * Horizon_SCAN]);
          // size of extracted cloud
          ++count;
        }
      }
      // last point that can be extracted; discard last 5 point of every ring
      cloudInfo.endRingIndex[i] = count - 1 - 5;
    }
  }

  void publishClouds()
  {
    cloudInfo.header = cloudHeader;
    // pub Extracted Cloud
    cloudInfo.cloud_deskewed = publishCloud(&pubExtractedCloud, extractedCloud, cloudHeader.stamp, lidarFrame);
    pubLaserCloudInfo.publish(cloudInfo);
  }

  void resetParameters()
  {
    laserCloudIn->clear();
    extractedCloud->clear();
    // reset range matrix for range image projection
    rangeMat = cv::Mat(N_SCAN, Horizon_SCAN, CV_32F, cv::Scalar::all(FLT_MAX));

    imuPointerCur = 0;
    firstPointFlag = true;
    odomDeskewFlag = false;

    for (int i = 0; i < queueLength; ++i)
    {
      imuTime[i] = 0;
      imuRotX[i] = 0;
      imuRotY[i] = 0;
      imuRotZ[i] = 0;
    }
  }

  void allocateMemory()
  {
    laserCloudIn.reset(new pcl::PointCloud<PointXYZIRT>());
    tmpOusterCloudIn.reset(new pcl::PointCloud<OusterPointXYZIRT>());
    fullCloud.reset(new pcl::PointCloud<PointType>());
    extractedCloud.reset(new pcl::PointCloud<PointType>());

    fullCloud->points.resize(N_SCAN * Horizon_SCAN);

    cloudInfo.startRingIndex.assign(N_SCAN, 0);
    cloudInfo.endRingIndex.assign(N_SCAN, 0);

    cloudInfo.pointColInd.assign(N_SCAN * Horizon_SCAN, 0);
    cloudInfo.pointRange.assign(N_SCAN * Horizon_SCAN, 0);

    resetParameters();
  }
};

int main(int argc, char **argv)
{
  ros::init(argc, argv, "lio_sam");
  ImageProjection IP;
  ROS_INFO("\033[1;32m----> Image Projection Started.\033[0m");
  // 这里原来是std::thread, 现在改成了ros MultiThreadedSpinner
  // 阻塞微调, 类似于ros::spin(), 你可以在它的构造函数中指定线程数量, 但如果不指定或者设为0, 它会根据你的CPU内核数创建线程.
  ros::MultiThreadedSpinner spinner(3); // perform callback function
  spinner.spin();
  return 0;
}